-- 1.Pre-requisite #######################################################
ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-hcatalog-core-1.1.0-cdh5.11.2.jar;

SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;

-- 2.creating workspace  #######################################################

-- drop database demo_study;
create database if not exists  demo_study;
use  demo_study;


-- 3.Loading data  #######################################################

-- drop  table demo_study.TLC_data; 

create external table if not exists demo_study.TLC_data(
VendorID int,
tpep_pickup_datetime timestamp,
tpep_dropoff_datetime timestamp,
passenger_count int,
trip_distance decimal(10,2),
RatecodeID int,
store_and_fwd_flag string,
PULocationID int,
DOLocationID int,
payment_type int,
fare_amount decimal(10,2),
extra decimal(10,2),
mta_tax decimal(10,2),
tip_amount decimal(10,2),
tolls_amount decimal(10,2),
improvement_surcharge decimal(10,2),
total_amount decimal(10,2)

)

ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/common_folder/nyc_taxi_data/'
tblproperties ("skip.header.line.count"="2"); 
-- skipping the header and blank row

-- querying table for validation
select * from demo_study.TLC_data;
select count(*) from demo_study.TLC_data;
-- 1174568




-- 4.sanity checks  #######################################################
--######### Basic Data Quality Checks
-- 1.How many records has each TPEP provider provided? 
-- Write a query that summarises the number of records of each provider.
select vendorid,count(*) from demo_study.TLC_data
group by vendorid;
-- 2	647183
--	1	527385
-- Vendor 2 has lager chuck of data
select 647183/1174568;
-- 55% od data belong to vendor2 , that leaves 45% of vendor 1

-- 4.A.check for empty cells   #######################################################
select sum(case when 	VendorID 	 is null then 1 else 0 end) 	VendorID 	,
sum(case when 	tpep_pickup_datetime 	 is null then 1 else 0 end) 	tpep_pickup_datetime 	,
sum(case when 	tpep_dropoff_datetime 	 is null then 1 else 0 end) 	tpep_dropoff_datetime 	,
sum(case when 	passenger_count 	 is null then 1 else 0 end) 	passenger_count 	,
sum(case when 	trip_distance 	 is null then 1 else 0 end) 	trip_distance 	,
sum(case when 	RatecodeID 	 is null then 1 else 0 end) 	RatecodeID 	,
sum(case when 	store_and_fwd_flag 	 is null then 1 else 0 end) 	store_and_fwd_flag 	,
sum(case when 	PULocationID 	 is null then 1 else 0 end) 	PULocationID 	,
sum(case when 	DOLocationID 	 is null then 1 else 0 end) 	DOLocationID 	,
sum(case when 	payment_type 	 is null then 1 else 0 end) 	payment_type 	,
sum(case when 	fare_amount 	 is null then 1 else 0 end) 	fare_amount 	,
sum(case when 	extra 	 is null then 1 else 0 end) 	extra 	,
sum(case when 	mta_tax 	 is null then 1 else 0 end) 	mta_tax 	,
sum(case when 	tip_amount 	 is null then 1 else 0 end) 	tip_amount 	,
sum(case when 	tolls_amount 	 is null then 1 else 0 end) 	tolls_amount 	,
sum(case when 	improvement_surcharge 	 is null then 1 else 0 end) 	improvement_surcharge 	,
sum(case when 	total_amount 	 is null then 1 else 0 end) 	total_amount 	
from demo_study.TLC_data;
-- all zero's

-- 4.B.range of data  
select max(VendorID ) max_VendorID	,	min(VendorID ) min_VendorID	,
max(tpep_pickup_datetime ) max_tpep_pickup_datetime	,	min(tpep_pickup_datetime ) min_tpep_pickup_datetime	,
max(tpep_dropoff_datetime ) max_tpep_dropoff_datetime	,	min(tpep_dropoff_datetime ) min_tpep_dropoff_datetime	,
max(passenger_count ) max_passenger_count	,	min(passenger_count ) min_passenger_count	,
max(trip_distance ) max_trip_distance	,	min(trip_distance ) min_trip_distance	,
max(RatecodeID ) max_RatecodeID	,	min(RatecodeID ) min_RatecodeID	,
max(store_and_fwd_flag ) max_store_and_fwd_flag	,	min(store_and_fwd_flag ) min_store_and_fwd_flag	,
max(PULocationID ) max_PULocationID	,	min(PULocationID ) min_PULocationID	,
max(DOLocationID ) max_DOLocationID	,	min(DOLocationID ) min_DOLocationID	,
max(payment_type ) max_payment_type	,	min(payment_type ) min_payment_type	,
max(fare_amount ) max_fare_amount	,	min(fare_amount ) min_fare_amount	,
max(extra ) max_extra	,	min(extra ) min_extra	,
max(mta_tax ) max_mta_tax	,	min(mta_tax ) min_mta_tax	,
max(tip_amount ) max_tip_amount	,	min(tip_amount ) min_tip_amount	,
max(tolls_amount ) max_tolls_amount	,	min(tolls_amount ) min_tolls_amount	,
max(improvement_surcharge ) max_improvement_surcharge	,	min(improvement_surcharge ) min_improvement_surcharge	,
max(total_amount ) max_total_amount	,	min(total_amount ) min_total_amount		
from demo_study.TLC_data;

--max_vendorid	min_vendorid	max_tpep_pickup_datetime	min_tpep_pickup_datetime
--	2           	1       	2018-01-01 00:04:00.0	    2003-01-01 00:58:00.0


--	max_tpep_dropoff_datetime	min_tpep_dropoff_datetime	max_passenger_count	min_passenger_count
--	2019-04-24 19:21:00.0	    2003-01-01 01:28:00.0	         9              	0

--max_trip_distance	min_trip_distance	max_ratecodeid	min_ratecodeid
--  126.41	           0	                99             	1

-- max_store_and_fwd_flag	min_store_and_fwd_flag	max_pulocationid	min_pulocationid
-- 	Y	                             N	                265	                 1

--max_dolocationid	min_dolocationid	max_payment_type	min_payment_type
--	265	              1                    	4                	1

--max_fare_amount	min_fare_amount	max_extra	min_extra
-- 	650	                -200	     4.8	      -10.6

--max_mta_tax	min_mta_tax	max_tip_amount	min_tip_amount
--	11.4	        -0.5	   450	           -1.16


--max_tolls_amount	min_tolls_amount	max_improvement_surcharge	min_improvement_surcharge
--  895.89	          -5.76	                    1	                        -0.3

--max_total_amount	min_total_amount
-- 928.19	           -200.8


-- column which seems to match the data disctionary #############################################################
-- pulocationid,dolocationid:- pickup and drop location are raning from 1 to 265
-- payment_type in data is spread between 1-4 which is with provided values of 1-4



--###################################################################################

-- columns that are not matching data dictionary
-- 4.C.Checking for remaining individual columns based on their range and metada provided #######################################################

-- vendorid is fine; values between two provider of 1 & 2

-- Basic Data Quality Checks######################
-- 2.The data provided is for months November and December only. 
-- Check whether the data is consistent, and if not, identify the data quality issues.
-- ###########################################################################
-- Mention all data quality issues in comments.
-- tpep_pickup_datetime #############################
-- the data is for two months Nov 2017 & Dec 2017
-- any day before 1-nov-2017 and after 31-dec-2017(represent as >= 1-jan-2018) is out of context
select count(*) from  demo_study.TLC_data 
where TLC_data.tpep_pickup_datetime < '2017-11-1 00:00:00.0' or tpep_pickup_datetime>='2018-01-01 00:00:00.0';
-- 14 records are not in the range
select  vendorid, count(*)from  demo_study.TLC_data 
where TLC_data.tpep_pickup_datetime < '2017-11-1 00:00:00.0' or tpep_pickup_datetime>='2018-01-01 00:00:00.0'
group by vendorid;
-- seems vendor 2 is at fault.
-- 2	14

-- tpep_dropoff_datetime ###################################################
-- The drop may have happened the next day hence the drop time is allowed to be till 1 jan 2018(represent as >= 2-jan-2018)
select count(*) from  demo_study.TLC_data 
where TLC_data.tpep_dropoff_datetime < '2017-11-1 00:00:00.0' or tpep_dropoff_datetime>='2018-01-02 00:00:00.0';
-- 7 records in total are not in range

select vendorid,count(*) from  demo_study.TLC_data 
where TLC_data.tpep_dropoff_datetime < '2017-11-1 00:00:00.0' or tpep_dropoff_datetime>='2018-01-02 00:00:00.0'
group by vendorid;
-- vendor 1 has 1 records
-- vendor 2 has 6 records
-- we will evaluate vendor 1 a lil more in details, since it has only 1 records
select * from  demo_study.TLC_data 
where (TLC_data.tpep_dropoff_datetime < '2017-11-1 00:00:00.0' or tpep_dropoff_datetime>='2018-01-02 00:00:00.0')
and vendorid=1;
-- seems like the data is corrupt one record ending far in future(2019)

-- drop of time can't be greater or equal to pick up time
select count(*) from demo_study.TLC_data 
where TLC_data.tpep_dropoff_datetime<=TLC_data.tpep_pickup_datetime;
-- 6555
select 6555/ 1174568;
-- 0.0055,a smaller set of records can be deleted/ignored
select vendorid, count(*) from demo_study.TLC_data 
where TLC_data.tpep_dropoff_datetime<=TLC_data.tpep_pickup_datetime
group by vendorid;
-- 1	3492
-- 2	3063
-- Vendor 1 seems to be at fault lets evaluate few of its records

select * from demo_study.TLC_data 
where TLC_data.tpep_dropoff_datetime<=TLC_data.tpep_pickup_datetime and vendorid=1;
-- well location id's for pick up and drop are changing and the billing seems to be different everytime
-- But since we can't be sure of what actual event took place and teh record set is small
-- we will ignore the records


-- passenger_count ######################################################################
select passenger_count, count(*) from  demo_study.TLC_data  group by passenger_count;
--passenger_count	_c1
--	0	6824
--	1	827498
--	2	176872
--	3	50693
--	4	24951
--	5	54568
--	6	33146
--	7	12
--	8	3
--	9	1

-- passenger count above 6 is small, like 7,8,9, may be bigger car, or driver manual entry mistake

select 6824/1174568;
--0.0058
-- 0 again seems like an disinterested driver not putting in details, or an empty parcel being sent in the cab
-- Lets see which vendor is at fault here
select vendorid,passenger_count, count(*) 
from  demo_study.TLC_data 
where passenger_count in  (0,7,8,9) group by vendorid,passenger_count
order by passenger_count,vendorid;
-- we will ignore 0 in passenger_count as the count or records are not too high and can be to be ignored

vendorid	passenger_count	_c2
 --	1	           0	    6813
--	2              0	     11
--	1	           7	      1
--	2	           7	     11
--	2	           8	      3
--	2	           9	      1
-- Vendor 1 seems to be at fault w.r.t 0 passenger_count


-- trip_distance ########################################
-- max_trip_distance,min_trip_distance
--      702.5,			0,
-- Data Dictionary:- The elapsed trip distance in miles reported by the taximeter.
select  count(*) from  demo_study.TLC_data where trip_distance<=0;
--7402 out of 1174568 small set
select 7402/1174568;
-- 0.0063
-- this data can be ignored
select  vendorid,count(*) from  demo_study.TLC_data where trip_distance<=0 group by vendorid;
vendorid	_c1
--	1	4217
--  2	3185
-- Both vendor seems to be equally responsible for this

-- ratecodeid ########################
select  ratecodeid,count(*) from  demo_study.TLC_data group by ratecodeid;
-- 1-6 are valid id as per the metadata, and 99 value based 9 records are incorrect 
-- we will ignore the 9 records
-- vendorid wise analysis
select vendorid , count(*) 
from  demo_study.TLC_data 
where ratecodeid=99
group by vendorid;
-- 1	8
-- 2	1
-- Vendor 1 is the mazor contributor towards this data discripency

-- store_and_fwd_flag ######################################################
select  store_and_fwd_flag,count(*) from  demo_study.TLC_data group by store_and_fwd_flag;
-- the value of yes and no are fine

-- fare_amount
-- max_fare_amount,min_fare_amount,
-- 680,       -200,
-- Data Dictionary :- The time-and-distance fare calculated by the meter.

select percentile_approx(fare_amount,array(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99))
from  demo_study.TLC_data;
-- [4.936277914662287,5.952247700797058,6.92251039282117,7.970874767979148,9.390659940336155,10.927988505747127,
-- 12.998791213590113,16.812362001498627,24.8522171486555,51.958303868698714]

-- these values are acceptable lets tru a smaller percentile value
select percentile_approx(fare_amount,array(0.01,0.999)) 
from  demo_study.TLC_data;
-- 	[3.261611065392163,88.10268000000157]
-- even these values are within range
-- seems like the negative values and very high values are wrong data or outliner.
-- we can easily ignore negative values
select count(*) from  demo_study.TLC_data where fare_amount<0;
-- 558 negative values
--  lets find a upper limit for these fare values
select count(*)
from  demo_study.TLC_data 
where fare_amount>100;
-- 770 records
-- let's try a bigger number
select count(*)
from  demo_study.TLC_data where fare_amount>500;
-- 1 record fall in this category 390000 values seems to be wrong
-- some these records have same pickup and drop location, may be the trip was circular
-- although all these values look like outliner , if we had businees team access we would have requested them to validate.
-- due to lack of grond to reject other values we will reject only 39 th and higher.
-- Vendor wise
select vendorid ,count(*)
from  demo_study.TLC_data
where fare_amount>500 or fare_amount<0  group by vendorid;
-- 1	1
-- 2	558
-- Vendor 2 is the major portion of the corrupt data

-- extra ##################################################################
-- max_extra,min_extra
-- 4.8,   -10.6
-- extra ranges between 4.8,   -10.6, as seen previously by the min and max query
-- But data dictionary says :-Miscellaneous extras and surcharges. 
-- Currently, this only includes the $0.50 and $1 rush hour and overnight charges.
-- hence we will reject these values let's verify their count
select count(*) from  demo_study.TLC_data where extra not in (0,0.5,1);
-- 4856
select 4856/1174568;
-- 0.0041 this data can be safely ignored
select vendorid,count(*) from  demo_study.TLC_data where extra not in (0,0.5,1)
 group by vendorid;
--  1	1823
--	2	3033
-- both vendro seems to at fault
-- may be the understanding w.r.t these extra column is missing 
-- as these are the only column where vendor 1 is also looking malicious

-- mta_tax  #################################################
-- max_mta_tax,min_mta_tax
-- 11.4     -0.5
-- Data Dictionary :-$0.50 MTA tax that is automatically triggered based on the metered rate in use.
select count(*) from  demo_study.TLC_data where mta_tax not in (0,0.5);
select 548/1174568;
--0.0004 smaller set, based on data disctionary we would ignore these
select vendorid,count(*) from  demo_study.TLC_data
where mta_tax not in (0,0.5) group by vendorid;
-- Both vendor are equally responsible, 
--  1		1
--	2		547
-- Vendor 2 is again mazorly at fault


-- tip_amount ###############################################################
-- max_tip_amount,min_tip_amount
--   450,            -1.16,
-- Data dictionary - Tip amount – This field is automatically populated for credit card tips. 
-- Cash tips are not included.
--negative values
select count(*) from  demo_study.TLC_data where tip_amount <0;
-- only 4 values are negative can be easily be ignored
select vendorid,count(*) from  demo_study.TLC_data 
where tip_amount <0 group by vendorid;
-- all 4 belongs to vendor 2

-- Let's chek if their are non credit card based tips
select count(*) from  demo_study.TLC_data where Payment_type!=1 and tip_amount>0;
-- 17 records have payment mode other than credit and still have tip amount greater than 0
-- we will ignore these records to sanity as well.

select vendorid,count(*) from  demo_study.TLC_data
where Payment_type!=1 and tip_amount>0  group by vendorid;
-- 1 17
-- All records belong to vendor 1
-- we will remove these records as well
-- tolls_amount ################################################################
-- max_tolls_amount,min_tolls_amount,
-- 895.89	          -5.76
-- Data Dictionary:- Total amount of all tolls paid in trip. 
-- The value can't be negative
select count(*) from  demo_study.TLC_data where tolls_amount <0;
-- only 3 records
select vendorid,count(*) from  demo_study.TLC_data
where tolls_amount <0
group by vendorid;
-- All vendor 2

-- improvement_surcharge#################################################
-- max_improvement_surcharge,min_improvement_surcharge,
--  1	                        -0.3
-- Data Dictionary :- $0.30 improvement surcharge assessed trips at the flag drop. The
-- improvement surcharge began being levied in 2015.
select count(*) from  demo_study.TLC_data where improvement_surcharge not in (0,0.3);
-- only 562  can be easily ignored
-- vendor wise
select vendorid,count(*) from  demo_study.TLC_data 
where improvement_surcharge not in (0,0.3) 
group by vendorid;
-- All records belong to vendor 2


-- total_amount #####################################################################
-- ,max_total_amount,min_total_amount
--  928.19	           -200.8
--Data Dictionary:-  The total amount charged to passengers. Does not include cash tips
-- can be negative and has similar high value as fare_amount, we will check this with similar queries
select count(*) from  demo_study.TLC_data where total_amount<0;
-- 558 can be easily ignored
-- Higehr value check
select * from  demo_study.TLC_data where total_amount>500;
-- 2 
-- vendor wise
select vendorid,count(*) from  demo_study.TLC_data 
where total_amount<0 
group by vendorid;
-- 2	558
-- vendor 2 is at fault


-- Basic Data Quality Checks ###########################################
-- 3.You might have encountered unusual or erroneous rows in the dataset. 
-- Can you conclude which vendor is doing a bad job in providing the records using different columns of the dataset? Summarise your conclusions based on every column where these errors are present.
-- For example,  There are unusual passenger count i.e 0 or 192 which is unusual.

-- For the data It's mostly vendor 2 that is providing faulty data.
-- Below is teh list of problemtic data they have provided column wise
-- invalid values for 1.total_amount , 2.improvement_surcharge,3.tolls_amount, 4.tip_amount,mta_tax, 
--  5.fare_amount,6.passenger_count, 7.pickup and 8.drop off time
-- ####################################
-- For the column extra both vendor seems to be equally at fault
-- Vendor 1 for has few tip amount where the payment mode is not credit card
-- ##########################################################
-- But overall Vendor 2 is definetely not providing correct data.

--###############################################################################################################

use demo_study;
-- Before answering the below questions, you need to create a clean, ORC partitioned table for analysis.
-- Remove all the erroneous rows.

-- We will be partinening on the month column first as we need to answer question comparing between the two
-- since we expect only two month data to pass from out filters year is not an any use in partionening

-- Our secondarly partition is based on Vendor , although the question don't call for this one
-- In general if we were analysing this data freely we would still want the partitionening to be done this way
-- drop table demo_study.ParOrc_TLC_data;
Create external table if not exists demo_study.ParOrc_TLC_data(
tpep_pickup_datetime timestamp,
tpep_dropoff_datetime timestamp,
passenger_count int,
trip_distance decimal(10,2),
RatecodeID int,
store_and_fwd_flag string,
PULocationID int,
DOLocationID int,
payment_type int,
fare_amount decimal(10,2),
extra decimal(10,2),
mta_tax decimal(10,2),
tip_amount decimal(10,2),
tolls_amount decimal(10,2),
improvement_surcharge decimal(10,2),
total_amount decimal(10,2)
)
partitioned by (Mnth int,VendorID int)
stored as orc location '/user/anurup.satyarth_gmail/case_study_orc'
tblproperties ("orc.compress"="SNAPPY");

-- Posting data
insert overwrite table demo_study.ParOrc_TLC_data partition(Mnth,VendorID)
select 
tpep_pickup_datetime,
tpep_dropoff_datetime,
passenger_count,
trip_distance,
RatecodeID,
store_and_fwd_flag,
PULocationID,
DOLocationID,
payment_type,
fare_amount,
extra,
mta_tax,
tip_amount,
tolls_amount,
improvement_surcharge,
total_amount,
month(tpep_pickup_datetime) Mnth,
VendorID
from  demo_study.TLC_data
where  (TLC_data.tpep_pickup_datetime >='2017-11-1 00:00:00.0' and tpep_pickup_datetime<'2018-01-01 00:00:00.0') and
( TLC_data.tpep_dropoff_datetime >= '2017-11-1 00:00:00.0' and tpep_dropoff_datetime<'2018-01-02 00:00:00.0') and
(TLC_data.tpep_dropoff_datetime>TLC_data.tpep_pickup_datetime) and
(passenger_count not in (0)) and
(trip_distance>0) and 
(ratecodeid!=99) and
(fare_amount>0 ) and
 (extra in (0,0.5,1)) and
 (mta_tax  in (0,0.5)) and 
((tip_amount >=0 and Payment_type=1) or (Payment_type!=1 and tip_amount=0)) and
( tolls_amount >=0) and
( improvement_surcharge in (0,0.3)) and
(total_amount>0 ) ;



select count(*) from demo_study.ParOrc_TLC_data;
--  1153586
select 1174568-1153586;
-- 20982 were removed
select (20982/1174568)*100;
-- amounting to 1.78% of data

-- Analysis-I ##################################################

-- 1 .Compare the overall average fare per trip for November and December.#########################################
select mnth,round(avg(total_amount),2),round(avg(fare_amount),2)
from demo_study.ParOrc_TLC_data  group by mnth;
-- mnth	  _c1   _c2
--	11	16.19	12.91
--	12	15.89	12.7
select 16.19-15.89, 12.91-12.7;
-- Overall the month Novemeber seems to be better considering total amount.
-- Also the difference in fare amount avg is on the lower side when compared to total amount
-- this signifies that exta tax and charges are also coming in play during the month of November

-- 2. Explore the ‘number of passengers per trip’ - how many trips are made by each level of ‘Passenger_count’? 
-- Do most people travel solo or with other people?#############################################################
select passenger_count,round((count(*)*100/1153586),4) cnt
from demo_study.ParOrc_TLC_data  group by passenger_count
order by cnt desc;
--passenger_count	cnt
--	1	70.8242
--	2	15.1513
--	5	4.6843
--	3	4.3502
--	6	2.8504
--	4	2.1394
--	7	0.0003
-- Solo rides are most common , dominant infact with almost 70% of data belonging to them
-- Dual rides are the only other significant category with 15% occupancy
-- Rest all are marfinal below 5 %
-- value for 9,8,7 are two small to be of any significance, may be special limo rides or corrupt data



-- 3.Which is the most preferred mode of payment? ##############################################################
select payment_type,round((count(*)*100/1153586),4) cnt
from demo_study.ParOrc_TLC_data  group by payment_type
order by cnt desc;
--payment_type	cnt

--	1	67.5418
--	2	31.9576
--	3	0.3884
--	4	0.1123
-- Credit card pays are dominant with 67.5% and cash payment are 2nd highest paymnet 32% approx
-- rest all modes are negligable
-- 5 & 6 are not existance as previsously seen.

-- 4.What is the average tip paid per trip? 
-- Compare the average tip with the 25th, 50th and 75th percentiles and 
-- comment whether the ‘average tip’ is a representative statistic (of the central tendency) of ‘tip amount paid’. 
-- Hint: You may use percentile_approx(DOUBLE col, p): 
-- Returns an approximate pth percentile of a numeric column (including floating point types) in the group.
select round(avg(tip_amount),2)  
from demo_study.ParOrc_TLC_data;
-- 1.83
select percentile_approx(tip_amount,array(0.25,0.40,0.45,0.50,0.60,0.65,0.75))  
from demo_study.ParOrc_TLC_data;
--   25%, 0.40, 0.45, 50%,  60%,  65%,  75%
-- 	[0.0, 0.99 , 1.45, 1.35, 1.75, 1.99, 2.44]
-- From the %centile values we can see that data is skewed towards the higher side.
-- 25% or more values bein zero tip do play a high part in this behaviour
-- again the median 1.35 is much lower then the avg 1.83 due to the skewness towards higher values
-- Hence mean is not representative statistic of centeral tendency here.
-- It would be advised to use median instead of mean for this particular column during analysis


-- 5. Explore the ‘Extra’ (charge) variable - what fraction of total trips have an extra charge is levied? ###############################################
select extra,round((count(*)*100/1153586),4) cnt from (
select case when extra>0 then 1 else 0 end  extra
from demo_study.ParOrc_TLC_data ) T
group by extra
order by cnt desc;
-- Extra applied    %age records
--      0	        53.8546
--      1	        46.1454
-- The distribusion is fairly even with 46.14% records having extra charges applied , where as  53.87% have no extra charges applied


-- Analysis-II ###########################################################################################################################

-- 1. What is the correlation between the number of passengers on any given trip, and the tip paid per trip? #########################################################
--    Do multiple travellers tip more compared to solo travellers? Hint: Use CORR(Col_1, Col_2)
select round(corr(passenger_count, tip_amount),4) from demo_study.ParOrc_TLC_data;
-- -0.0053
-- the value is fairly small although negative but its would be fair to say that passenger count is unrealted to the tip amount paid.
select round(corr(is_solo, tip_amount),4) from 
(select case when passenger_count=1 then 1 else 0 end is_solo,tip_amount 
from demo_study.ParOrc_TLC_data ) T;
-- 0.0062, comparing only single vs multiple rider count their is still very low co-relation
select is_solo,round(avg(tip_amount),4) from 
(select case when passenger_count=1 then 1 else 0 end is_solo,tip_amount 
from demo_study.ParOrc_TLC_data ) T group by is_solo;
--  0	1.8023
--	1	1.8354
-- Values are almost same 



-- 2. Segregate the data into five segments of ‘tip paid’: [0-5), [5-10), [10-15) , [15-20) and >=20. #######################################################
--    Calculate the percentage share of each bucket (i.e. the fraction of trips falling in each bucket).
select Tip_range, round((count(*)*100/1153586),4) cnt
from (select
case when (tip_amount>=0 and tip_amount<5)   then '[0-5)' 
     when (tip_amount>=5 and tip_amount<10)  then '[5-10)' 
     when (tip_amount>=10 and tip_amount<15) then '[10-15)'
     when (tip_amount>=15 and tip_amount<20) then '[15-20)'
     when (tip_amount>=20)                   then '>=20' end Tip_range
     from demo_study.ParOrc_TLC_data) T 
     group by Tip_range
     order by cnt desc;
--tip_range	cnt
--	[0-5)	92.4038
--	[5-10)	5.638
--	[10-15)	1.6829
--	[15-20)	0.1872
--	>=20	0.0881
-- 0-5 range is the most prominate group with 92.4% records, we already know 25%+ of these are 0 values from the precious percentile based check
-- 5-10 represening a small fraction of 5.6%, remaning set are almost negligible amount to 2% of data

-- 3.Which month has a greater average ‘speed’ - November or December? ##################################################
-- Note that the variable ‘speed’ will have to be derived from other metrics.
-- Hint: You have columns for distance and time.

-- we will calculate duratiob by suntaring drop of time with pick uo time, since we are using unix timestamp function(as direct suntraction of timestamp column didn't work)
-- values will be returned in sec hence we will be dividing it by 3600 to get value sin hour
-- since distance is psecified in miles out final value will be in miles/hour unit

select mnth , round(avg(trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600) ),2) avg_speed
from demo_study.ParOrc_TLC_data
group by mnth
order by avg_speed desc;
--  11	10.97
--	12	11.07

select 11.07-10.97;
-- Novenmeber month is marginally faster by 0.09 miles/hour
-- this is unexpected that during the holiday seasons of december taxi are running slow
-- but the minimilatic difference represents that NewYork never rest it works even through its holiday season



-- 5.Analyse the average speed of the most happening days of the year, #########################################################################################
-- i.e. 31st December (New year’s eve) and 25th December (Christmas Eve)
-- and compare it with the overall average. 

-- any trip that started on 25th or 31 will be considerd for the avg calculation irrespective of the fact that it might have ended on the next day
select IsHoliday, round(avg(speed),2) avg_speed from 
(select case when ((tpep_pickup_datetime>='2017-12-25 00:00:00.0' and tpep_pickup_datetime<'2017-12-26 00:00:00.0') 
or (tpep_pickup_datetime>='2017-12-31 00:00:00.0' and tpep_pickup_datetime<'2018-01-01 00:00:00.0')  ) then 1 else 0 end IsHoliday   , 
trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600) speed
from demo_study.ParOrc_TLC_data) T
group by IsHoliday
order by avg_speed desc;
-- 1	14.01
-- 0	10.95
select 14.01-10.95;
-- The comparision between holiday vs non-holiday , the during the holiday atleast the streets of New York are clear(er)
-- as the Cab's are running at a faster average speed by a margin of  3.06 miles/hour
-- The non festive day average is in sync with november and december averages at around 10.95 miles/per hour
-- let's confirm teh overall averages once
select round(avg(trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600)),2) avg_speed
from demo_study.ParOrc_TLC_data;
-- 11.02 is the overall avg speed as expected so the faster speed on 25th and 31 dec amounts to 0.05(12.61 was for non holiday days) increment on the overall speed 

-- Let's compare individual days too
-- christmas
select Day_type,round(avg(trip_distance/((unix_timestamp(tpep_dropoff_datetime)-unix_timestamp(tpep_pickup_datetime) )/3600)),2) avg_speed
from ( 
select trip_distance,tpep_dropoff_datetime,tpep_pickup_datetime,
case when ((tpep_pickup_datetime>='2017-12-25 00:00:00.0' and tpep_pickup_datetime<'2017-12-26 00:00:00.0')) then 1
when ((tpep_pickup_datetime>='2017-12-31 00:00:00.0' and tpep_pickup_datetime<'2018-01-01 00:00:00.0')  ) then 2 else 0 end Day_type 
from demo_study.ParOrc_TLC_data
) T
group by Day_type;

--  0	10.95 rest of the days
--	1	15.27 Chritsmas
--  2	13.24 new year eve
-- The fasted avg speed is oberved on chrismat day @ 15.27 miles/hour; 2.03 miles/hour faster than new year eve mark of 13.24 miles/hour
-- The result represent similar value to the combined is-holiday data i.e. Both are indidvidually much faster than the average time taken on other days  